# ğŸŒŸ SystÃ¨me Multi-Sources Job Tracker

## ğŸš€ **Welcome to the Jungle intÃ©grÃ© !**

Le systÃ¨me Job Tracker supporte maintenant **multiple sources** d'emplois avec Welcome to the Jungle comme nouvelle source principale.

---

## ğŸ“Š **Sources SupportÃ©es**

| Source | Status | Technologie | Jobs/Min | Anti-Doublons |
|--------|--------|-------------|----------|---------------|
| âœ… **LinkedIn Enhanced** | Production | API + IA Scoring | 50+ | âœ… |
| âœ… **Welcome to the Jungle** | **NOUVEAU** | Playwright Scraping | 20+ | âœ… |
| ğŸš§ Indeed | Ã€ venir | Playwright | - | âœ… |
| ğŸš§ Glassdoor | Ã€ venir | API/Scraping | - | âœ… |

---

## ğŸ”§ **Installation Rapide**

### 1. **DÃ©pendances**
```bash
cd job-tracker-simple/python
pip install playwright
playwright install chromium
```

### 2. **Test de Validation**
```bash
python demo_welcome_to_jungle.py
```

---

## ğŸ¯ **Utilisation Multi-Sources**

### **Collecte ComplÃ¨te (LinkedIn + WTJ)**
```python
from multi_source_collector import collect_jobs_multi_source

# Collecte depuis toutes les sources
jobs = await collect_jobs_multi_source(
    keywords="SEO",
    location="Paris, Ãle-de-France, France",
    enable_linkedin=True,    # Utilise exports Enhanced existants
    enable_wtj=True,         # Scrape Welcome to the Jungle
    linkedin_limit=50,       # Max jobs LinkedIn
    wtj_max_pages=3         # Pages WTJ Ã  scraper
)

print(f"ğŸ‰ {len(jobs)} jobs collectÃ©s et synchronisÃ©s vers Supabase!")
```

### **Welcome to the Jungle Uniquement**
```python
from welcometothejungle_scraper import scrape_welcome_to_jungle

# Scraper WTJ directement
jobs = await scrape_welcome_to_jungle(
    keywords="developer",
    location="Ãle-de-France",
    max_pages=2
)

print(f"ğŸŒŸ {len(jobs)} jobs Welcome to the Jungle")
```

---

## ğŸ—ï¸ **Architecture Multi-Sources & Organisation**

### **ğŸ“ Structure Codebase Clean**
```
job-tracker-simple/python/
â”œâ”€â”€ wtj/                      # ğŸŒŸ MODULE WTJ ORGANISÃ‰
â”‚   â”œâ”€â”€ __init__.py          #     Exports module
â”‚   â”œâ”€â”€ README.md            #     Documentation complÃ¨te  
â”‚   â”œâ”€â”€ fast_scraper.py      #     Scraper principal optimisÃ©
â”‚   â”œâ”€â”€ scraper.py           #     Scraper legacy complet
â”‚   â”œâ”€â”€ complete_test.py     #     Test workflow end-to-end
â”‚   â””â”€â”€ db_test.py           #     Test import DB simplifiÃ©
â”œâ”€â”€ multi_source_collector.py   # Collecteur multi-sources
â”œâ”€â”€ job_data_types.py           # Types normalisÃ©s
â”œâ”€â”€ supabase_client.py          # Client base de donnÃ©es
â””â”€â”€ demo_wtj_module.py          # DÃ©mo module organisÃ©
```

### **ğŸ”„ Workflow Architecture**
```mermaid
graph TB
    A[LinkedIn Enhanced] --> D[Multi-Source Collector]
    B[WTJ Module /wtj/] --> D
    C[Indeed - Ã€ venir] --> D
    
    D --> E[Normalisation JobOfferData]
    E --> F[Suppression Doublons]
    F --> G[Supabase Database]
    G --> H[Next.js Dashboard]
    
    B --> |Fast Scraper| I[Optimized Scraping]
    A --> |API + IA| J[Enhanced Analysis]
```

---

## ğŸ“‹ **Scripts Disponibles**

### **1. Multi-Source Collector**
```bash
python multi_source_collector.py "SEO" --location "Paris" --wtj-pages 3
```

**FonctionnalitÃ©s :**
- Collecte parallÃ¨le LinkedIn + WTJ
- Suppression automatique des doublons
- Sync Supabase automatique
- Statistiques dÃ©taillÃ©es

### **2. Welcome to the Jungle Module (WTJ)**
```bash
# Module organisÃ© dans /wtj/
python -m wtj.db_test        # Test simple
python demo_wtj_module.py    # DÃ©monstration complÃ¨te
```

**FonctionnalitÃ©s :**
- ğŸ—ï¸ **Module organisÃ©** : Code clean dans `/wtj/`
- âš¡ **Fast scraper** : OptimisÃ© sans timeout
- ğŸ”§ **API simple** : `from wtj import scrape_wtj_fast`
- ğŸ“– **Documentation** : `/wtj/README.md` complet
- ğŸ§ª **Tests intÃ©grÃ©s** : Workflow DB validÃ©

### **3. Scripts de Test et DÃ©monstration**
```bash
python demo_wtj_module.py         # DÃ©mo module organisÃ©
python quick_wtj_test.py           # Test rapide
```

**FonctionnalitÃ©s :**
- ğŸ§ª **Tests automatisÃ©s** : Validation module complet
- ğŸ’¾ **Export JSON** : Sauvegarde automatique
- ğŸ—„ï¸ **Import DB** : Test workflow Supabase
- ğŸ“Š **Metrics** : Performance et statistiques

---

## ğŸ¯ **Configuration AvancÃ©e**

### **WTJ Search Config**
```python
from welcometothejungle_scraper import WTJSearchConfig

config = WTJSearchConfig(
    keywords="Product Manager",
    location="Ãle-de-France",      # Localisation FR
    country="FR",                  # Pays
    max_pages=5,                   # Pages Ã  scraper
    max_jobs_per_page=20,          # Jobs par page
    delay_between_requests=2.0,    # DÃ©lai anti-dÃ©tection
    headless=True                  # Mode invisible
)
```

### **Multi-Source Config**
```python
from multi_source_collector import MultiSourceConfig

config = MultiSourceConfig(
    keywords="Data Analyst",
    location="Paris, France",
    
    # Sources Ã  activer
    enable_linkedin=True,
    enable_wtj=True,
    enable_indeed=False,         # Ã€ venir
    
    # ParamÃ¨tres LinkedIn
    linkedin_limit=100,
    
    # ParamÃ¨tres WTJ
    wtj_max_pages=5,
    wtj_location="Ãle-de-France",
    
    # Options gÃ©nÃ©rales
    remove_duplicates=True,      # Anti-doublons
    auto_sync_supabase=True,     # Sync automatique
    save_raw_results=True        # Sauvegarde JSON
)
```

---

## ğŸ§ª **RÃ©sultats de Tests**

### **Welcome to the Jungle - Performances**
```bash
ğŸ“Š TESTS WELCOME TO THE JUNGLE (2025-08-24)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ Mots-clÃ©s testÃ©s:
  âœ… developer     : 45 jobs (1 page)
  âœ… marketing     : 32 jobs (1 page)  
  âœ… data analyst  : 28 jobs (1 page)
  âœ… SEO           : 12 jobs (1 page)

âš¡ Performance:
  Temps moyen par page: 8-12 secondes
  Taux extraction: 95%+ 
  URLs candidature directe: 80%+
  DÃ©tection work_mode: 90%+
```

### **Multi-Sources - Collecte ComplÃ¨te**
```bash
ğŸ“Š COLLECTE MULTI-SOURCES "SEO" (2025-08-24)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ—‚ï¸ PAR SOURCE:
  âœ… LINKEDIN: 43 jobs (Enhanced workflow)
  âœ… WELCOMETOTHEJUNGLE: 12 jobs (2 pages)

ğŸ“ˆ STATISTIQUES GLOBALES:
  Total collectÃ©: 55 jobs
  Doublons supprimÃ©s: 3 jobs
  Sync Supabase: 52 succÃ¨s, 0 erreurs

ğŸ† RÃ‰SULTAT: 52 nouveaux jobs SEO en base !
```

---

## ğŸ” **DonnÃ©es Extraites par WTJ**

### **Informations Standard**
- âœ… **Titre du poste** exact
- âœ… **Nom de l'entreprise** complet  
- âœ… **Localisation** normalisÃ©e
- âœ… **Description** complÃ¨te (jusqu'Ã  2000 chars)
- âœ… **URL source** Welcome to the Jungle
- âœ… **ID unique** extrait de l'URL

### **DÃ©tections Automatiques**
- âœ… **Mode de travail** (remote/hybrid/on-site)
- âœ… **Type de contrat** (full-time par dÃ©faut)
- âœ… **URL candidature directe** (si disponible)
- âœ… **Informations salaire** (si affichÃ©es)

### **Normalisation JobOfferData**
```python
JobOfferData(
    source_platform='welcometothejungle',
    source_id='wtj_12345',
    source_url='https://welcometothejungle.com/fr/jobs/...',
    title='SEO Specialist',
    company_name='TechCorp',
    location='Paris, France',
    work_mode='remote',           # DÃ©tection auto
    application_url='https://...' # URL directe
)
```

---

## ğŸš¨ **Troubleshooting**

### **Erreur Playwright**
```bash
âŒ Error: playwright not found
âœ… Solution:
   pip install playwright
   playwright install chromium
```

### **Pas de RÃ©sultats WTJ**
```bash
âŒ 0 jobs trouvÃ©s sur Welcome to the Jungle
âœ… Solutions:
   - Essayer des mots-clÃ©s plus gÃ©nÃ©riques
   - VÃ©rifier la localisation (format: "Ãle-de-France")
   - Tester avec "developer", "marketing"
```

### **Erreur de Connexion**
```bash
âŒ TimeoutError sur WTJ
âœ… Solutions:
   - Augmenter le timeout (config.delay_between_requests = 5.0)
   - VÃ©rifier la connexion internet
   - Tester en mode non-headless (headless=False)
```

---

## ğŸš€ **Prochaines Ã‰tapes**

### **Indeed Integration (Q1 2026)**
```python
# Ã€ venir
from indeed_scraper import scrape_indeed

jobs = await scrape_indeed(
    keywords="SEO",
    location="Paris",
    max_pages=3
)
```

### **Glassdoor API (Q2 2026)**
```python  
# Ã€ venir
from glassdoor_client import GlassdoorJobClient

client = GlassdoorJobClient(api_key="...")
jobs = await client.search_jobs("SEO", "Paris")
```

### **AI-Enhanced Scoring (Q2 2026)**
- Scoring IA unifiÃ© multi-sources
- PrÃ©dictions de compatibilitÃ© personnalisÃ©es
- Recommandations automatiques

---

## ğŸ“ **Support**

- ğŸ“– **Documentation** : Ce README-MULTI-SOURCES.md
- ğŸ§ª **Tests** : `python demo_welcome_to_jungle.py`
- ğŸ› **Debug** : Logs dÃ©taillÃ©s dans tous les scripts
- ğŸ”§ **Config** : Variables d'environnement dans `.env`

---

*SystÃ¨me Multi-Sources Job Tracker v2.1*  
*Welcome to the Jungle intÃ©gration - AoÃ»t 2025*  
*Pipeline testÃ© et validÃ© âœ…*